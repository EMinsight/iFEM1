{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alive-hungary",
   "metadata": {},
   "source": [
    "Preconditioning\n",
    "===\n",
    "\n",
    "We call $C$ a preconditioner to the matrix $A$ if \n",
    "* $C^{-1} A \\approx I$\n",
    "* the matrix-vector multiplication $w = C^{-1} r$ is cheap\n",
    "\n",
    "One extreme case is $C = A$, where the first claim is optimally satisfied, but (in general) not the second. The opposite extreme is $C = I$. \n",
    "\n",
    "If $A$ is an SPD matrix, we like to have an SPD preconditioner $C$. In this case, the quality of the approximation can be measured by the spectral bounds\n",
    "\n",
    "$$\n",
    "0 < \\gamma_1 \\leq \\frac{x^T A x }{x^T C x} \\leq \\gamma_2 \\qquad \\forall \\, 0 \\neq x \\in {\\mathbb R^n}\n",
    "$$\n",
    "\n",
    "These spectral bounds are bounds for the eigenvalues $\\lambda$ of the generalized eigenvalue problem\n",
    "\n",
    "$$\n",
    "A x = \\lambda C x\n",
    "$$\n",
    "\n",
    "If $\\lambda_i$ is an eigenvalue with eigenvector $x_i$, then $x_i^T A x_i = \\lambda_i x_i^T C x_i$, and thus $\\lambda_i \\in [\\gamma_1, \\gamma_2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-popularity",
   "metadata": {},
   "source": [
    "The preconditioned Richardson iteration\n",
    "---\n",
    "We use the preconditioner to obtain the correction from the residuum:\n",
    "\n",
    "$$\n",
    "\\qquad  x^{k+1} = x^k - \\alpha C^{-1} (b - A x^k)\n",
    "$$\n",
    "\n",
    "The error is now propagated as\n",
    "\n",
    "$$\n",
    "e^{k+1} = M e^k = (I - \\alpha C^{-1} A) e^k\n",
    "$$\n",
    "\n",
    "The error-propagation matrix $M$ is self-adjoint in the energy inner product\n",
    "\\begin{eqnarray*}\n",
    "\\left< M x, y \\right>_A & = & \\left\\{ A (x - \\alpha C^{-1} A x) \\right\\}^T y  \\\\\n",
    "& = & x^T (A - \\alpha A C^{-1} A) y \\\\\n",
    "& = & \\left< x, M y \\right>_A\n",
    "\\end{eqnarray*}\n",
    "\n",
    "as well as in the inner products\n",
    "$$\n",
    "\\left< x, y \\right>_C \\qquad \\text{and} \\qquad \\left< x, y \\right>_{AC^{-1} A}.\n",
    "$$\n",
    "The error is monotonically decreased in the corresponding norms. In particular the last one is practically interesting since it is computationally available:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\| x - x^\\ast \\|_{AC^{-1} A}^2 & = & \\| A (x - x^\\ast) \\|_{C^-1}^2 \\\\\n",
    "& = & \\| A x - b \\|_{C^{-1}}^2\n",
    "\\end{eqnarray*}\n",
    "\n",
    "With the residuum $r$ and preconditioned residuum $w$, i.e.\n",
    "\n",
    "$$\n",
    "r = b - A x \\qquad \\text{and} \\qquad w = C^{-1} r\n",
    "$$\n",
    "\n",
    "the error becomes\n",
    "\n",
    "$$\n",
    "\\| x - x^\\ast \\|_{AC^{-1}A}^2 = r^T w\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngsolve import *\n",
    "from netgen.geom2d import unit_square\n",
    "mesh = Mesh(unit_square.GenerateMesh(maxh=0.1))\n",
    "fes = H1(mesh, order=1)\n",
    "u,v = fes.TnT()\n",
    "a = BilinearForm(grad(u)*grad(v)*dx+10*u*v*dx).Assemble()\n",
    "f = LinearForm(x*y*v*dx).Assemble()\n",
    "gfu = GridFunction(fes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-audit",
   "metadata": {},
   "source": [
    "A very simple preconditioner is the Jacobi-preconditioner\n",
    "\n",
    "$$\n",
    "C = \\text{diag} A\n",
    "$$ \n",
    "\n",
    "If $A$ is SPD, then all diagonal entries are positive, and $C$ is SPD as well.\n",
    "\n",
    "In NGSolve, we can obtain a Jacobi preconditioner as follows. The result is a linear operator providing the linear operation\n",
    "\n",
    "$$\n",
    "w := C^{-1} * r\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "cinv = a.mat.CreateSmoother()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv = gfu.vec.CreateVector()\n",
    "hv2 = gfu.vec.CreateVector()\n",
    "hv3 = gfu.vec.CreateVector()\n",
    "hv.SetRandom()\n",
    "hv.data /= Norm(hv)\n",
    "for k in range(20):\n",
    "    hv2.data = a.mat * hv\n",
    "    hv3.data = cinv * hv2\n",
    "    rho = Norm(hv3)\n",
    "    print (rho)\n",
    "    hv.data = 1/rho * hv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1 / rho\n",
    "r = f.vec.CreateVector()\n",
    "w = f.vec.CreateVector()\n",
    "gfu.vec[:] = 0\n",
    "\n",
    "w.data = cinv * f.vec\n",
    "err0 = sqrt(InnerProduct(f.vec, w))\n",
    "its = 0\n",
    "while True:\n",
    "    r.data = f.vec - a.mat * gfu.vec\n",
    "    w.data = cinv * r\n",
    "    err = sqrt(InnerProduct(r,w))\n",
    "    print (\"iteration\", its, \"res=\", err)\n",
    "    gfu.vec.data += alpha * w\n",
    "    if err < 1e-8 * err0 or its > 10000: break\n",
    "    its = its+1\n",
    "print (\"needed\", its, \"iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-stretch",
   "metadata": {},
   "source": [
    "By situation is not considerably improved by the diagonal preconditioner. However, if we have a bilinear-form with variable coefficient, or large coefficients in the Robin - boundary condition such as\n",
    "\n",
    "$$\n",
    "A(u,v) = \\int_\\Omega \\nabla u \\nabla v \\, dx + 10^8 \\int_{\\Gamma_R} u v \\, ds,\n",
    "$$\n",
    "\n",
    "the Jacobi preconditioner captures these parameters (experiment in  excercise, theory soon)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-sheriff",
   "metadata": {},
   "source": [
    "The preconditioned gradient method\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-combine",
   "metadata": {},
   "source": [
    "To introduce the preconditioner into the gradient method we proceed as follows. Since $C$ is SPD, we are allowed to form its square-root\n",
    "\n",
    "$$\n",
    "C^{1/2}\n",
    "$$\n",
    "\n",
    "as well as its inverse. The linear system $A x = b$ is equivalent to \n",
    "\n",
    "$$\n",
    "C^{-1/2} A C^{-1/2} \\; C^{1/2} x = C^{-1/2} b.\n",
    "$$\n",
    "\n",
    "With the definition of transformed quantities \n",
    "\n",
    "$$\n",
    "\\tilde A = C^{-1/2} A C^{-1/2}, \\qquad\n",
    "\\tilde b = C^{-1/2} b, \\qquad\n",
    "\\tilde x = C^{1/2} x\n",
    "$$\n",
    "\n",
    "we have the linear system\n",
    "\n",
    "$$\n",
    "\\tilde A \\tilde x = \\tilde b\n",
    "$$\n",
    "\n",
    "The transformed matrix $\\tilde A$ is SPD as well.\n",
    "\n",
    "We apply the gradient method for the transformed system:\n",
    "\n",
    "Given $\\tilde x^0$ <br>\n",
    "$\\tilde r^0 = \\tilde b - \\tilde A \\tilde x^0$ <br>\n",
    "for $k = 0, 1, 2, \\ldots$ <br>\n",
    "$\\qquad \\tilde p = \\tilde A \\tilde r^k$ <br>\n",
    "$\\qquad \\alpha = {\\tilde r^k}^T \\tilde r^k \\, / \\, {\\tilde r^k}^T \\tilde p$ <br>\n",
    "$\\qquad \\tilde x^{k+1} = \\tilde x^k + \\alpha \\tilde r^k$ <br>\n",
    "$\\qquad \\tilde r^{k+1} = \\tilde r^k - \\alpha \\tilde p$ <br>\n",
    "\n",
    "\n",
    "Now we transform back via\n",
    "$$\n",
    "\\tilde x^k = C^{1/2} x^k, \\qquad \\tilde r^k = C^{-1/2} r, \n",
    "\\qquad \\tilde p = C^{-1/2} p\n",
    "$$\n",
    "and obtain\n",
    "\n",
    "Given $x^0$ <br>\n",
    "$C^{-1/2} r^0 = C^{-1/2} b  - C^{-1/2} A C^{-1/2} C^{1/2} x^0$ <br>\n",
    "for $k = 0, 1, 2, \\ldots$ <br>\n",
    "$\\qquad C^{-1/2} p = C^{-1/2} A C^{-1/2} C^{-1/2} r^k$ <br>\n",
    "$\\qquad \\alpha = \\frac{\\{C^{-1/2} r^k \\}^T C^{-1/2} r^k \\, }{ \\, \\{ C^{-1/2} r^k\\}^T C^{-1/2} p}$ <br>\n",
    "$\\qquad C^{1/2} x^{k+1} = C^{1/2} x^k + \\alpha C^{-1/2} r^k$ <br>\n",
    "$\\qquad C^{-1/2} r^{k+1} = C^{-1/2} r^k - \\alpha C^{-1/2} p$ <br>\n",
    "\n",
    "now we simplify, and introduce $w = C^{-1} r$\n",
    "\n",
    "Given $x^0$ <br>\n",
    "$r^0 = b - A x^0$ <br>\n",
    "for $k = 0, 1, 2, \\ldots$ <br>\n",
    "$\\qquad w = C^{-1} r$ <br>\n",
    "$\\qquad p = A w$ <br>\n",
    "$\\qquad \\alpha = \\frac{w^T r^k}{w^T p^k}$ <br>\n",
    "$\\qquad x^{k+1} = x^k + \\alpha w$ <br>\n",
    "$\\qquad r^{k+1} = r^k - \\alpha p$ <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = f.vec.CreateVector()\n",
    "w = f.vec.CreateVector()\n",
    "p = f.vec.CreateVector()\n",
    "\n",
    "gfu.vec[:] = 0\n",
    "r.data = f.vec\n",
    "w.data = pre*r\n",
    "err0 = sqrt(InnerProduct(r,w))\n",
    "its = 0\n",
    "while True:\n",
    "    w.data = pre*r\n",
    "    p.data = a.mat * w\n",
    "    err2 = InnerProduct(w,r)\n",
    "    alpha = err2 / InnerProduct(w,p)\n",
    "\n",
    "    print (\"iteration\", its, \"res=\", sqrt(err2))\n",
    "    gfu.vec.data += alpha * w\n",
    "    r.data -= alpha * p\n",
    "    if sqrt(err2) < 1e-8 * err0 or its > 10000: break\n",
    "    its = its+1\n",
    "print (\"needed\", its, \"iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-protest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
